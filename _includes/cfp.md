## ðŸ“¢ <a id="cfp"></a> Call for Papers

We focus on bridging the gap between the growing capabilities of multimodal machine learning models and the urgent needs of real-world applications in under-resourced, marginalized, or data-constrained settings. This includes scenarios where data is scarce, modalities are incomplete or imbalanced, and computational or human infrastructure may be limited.

The topics of interest include, but are not limited to:

- **Learning with Missing or Incomplete Modalities**  
  Techniques for modality dropout, hallucination, and imputation when input signals are sparse or missing at training or inference time.

- **Few-Shot, Zero-Shot, and Transfer Learning in Multimodal Contexts**  
  Approaches that allow models pre-trained on high-resource datasets to adapt effectively to novel, low-resource domains and languages.

- **Multilingual and Multimodal Representation Learning**  
  Unifying language, vision, audio, and other modalities across multiple languages, especially those underrepresented in current benchmarks.

- **Ethical, Interpretable, and Responsible AI for Multimodal Systems**  
  Auditing and mitigating bias in multimodal systems; developing transparent models that explain decisions across modalities in high-stakes domains.

- **Benchmarking and Evaluation for Real-World Robustness**  
  Proposing new datasets, metrics, and evaluations that reflect deployment challenges in regions with limited resources or infrastructure.

- **Applications in Social Good**, including:
  - Ecological and biodiversity monitoring (e.g., combining satellite, image, and audio data)
  - Public health and epidemiology in underserved regions
  - Language documentation and cultural preservation
  - Crisis response, misinformation detection, and social justice

