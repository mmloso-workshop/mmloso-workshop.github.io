---
layout: default
title: Welcome to MMLoSo 2025
---

<style>
body {
  max-width: 850px;
  margin: 0 auto;
  padding: 20px;
}
nav {
  margin-bottom: 2em;
  text-align: center;
}
nav a {
  display: inline-block;
  margin: 5px;
  padding: 10px 18px;
  background-color: #005a9c;
  color: white;
  border-radius: 6px;
  text-decoration: none;
}
.organizers {
  display: flex;
  flex-wrap: wrap;
  gap: 20px;
  justify-content: center;
  margin-top: 20px;
}
.organizers div {
  text-align: center;
  flex: 1 1 180px;
}
.organizers img {
  width: 120px;
  height: 120px;
  border-radius: 50%;
  object-fit: cover;
}
</style>

# MMLoSo Workshop @ IJCNP-AACL 2025
_First International Workshop on Multimodal Models for Low-Resource Contexts and Social Impact_

[üîó View on OpenReview](https://openreview.net/group?id=aclweb.org/AACL-IJCNLP/2025/Workshop/MMLoSo)

<nav>
  <a href="#about">About</a>
  <a href="#cfp">Call for Papers</a>
  <a href="#dates">Important Dates</a>
  <a href="#organizers">Organizers</a>
  <a href="#contact">Contact</a>
</nav>

---

## üìñ <a id="about"></a> About

This workshop brings together researchers at the intersection of multimodal learning, NLP, and AI for social good, with a focus on low-resource and underserved settings. While multimodal data‚Äîtext, audio, visual, and sensor‚Äîcontinues to grow, most state-of-the-art models depend on large, high-quality datasets, limiting their applicability in data-scarce environments.

We invite papers on developing robust and inclusive multimodal systems that can operate effectively under data constraints. Topics include learning with multiple modalities, cross-lingual, cross-modal adaptation, and interpretable models for domains like healthcare, ecological monitoring, education, and cultural heritage preservation. Alongside papers and keynotes, a community-driven shared task will evaluate multimodal robustness and generalization in low-resource contexts. 

---

## üì¢ <a id="cfp"></a> Call for Papers

We focus on bridging the gap between the growing capabilities of multimodal machine learning models and the urgent needs of real-world applications in under-resourced, marginalized, or data-constrained settings. This includes scenarios where data is scarce, modalities are incomplete or imbalanced, and computational or human infrastructure may be limited.

The topics of interest for the workshop include, but are not limited to:

- **Learning with Missing or Incomplete Modalities**  
  Techniques for modality dropout, hallucination, and imputation when input signals are sparse or missing at training or inference time.

- **Few-Shot, Zero-Shot, and Transfer Learning in Multimodal Contexts**  
  Approaches that allow models pre-trained on high-resource datasets to adapt effectively to novel, low-resource domains and languages.

- **Multilingual and Multimodal Representation Learning**  
  Unifying language, vision, audio, and other modalities across multiple languages, especially those underrepresented in current benchmarks.

- **Ethical, Interpretable, and Responsible AI for Multimodal Systems**  
  Auditing and mitigating bias in multimodal systems; developing transparent models that explain decisions across modalities in high-stakes domains.

- **Benchmarking and Evaluation for Real-World Robustness**  
  Proposing new datasets, metrics, and evaluations that reflect deployment challenges in regions with limited resources or infrastructure.

- **Applications in Social Good**, including:
  - Ecological and biodiversity monitoring (e.g., combining satellite, image, and audio data)
  - Public health and epidemiology in underserved regions
  - Language documentation and cultural preservation
  - Crisis response, misinformation detection, and social justice

---

## üìÖ <a id="dates"></a> Important Dates  
*(Subject to change based on IJCNLP-AACL 2025)*

- üìù Submission Deadline: **September 29, 2025**  
- üì¢ Notification: **November 3, 2025**  
- üñã Camera-ready Deadline: **November 11, 2025**  
- üìç Workshop: **December 23, 2025**

---

## üë• <a id="organizers"></a> Organizers
<div class="organizers">
  <div>
    <img src="/assets/img/ankita.jpeg" alt="Ankita Shukla"><br>
    <strong>Ankita Shukla</strong><br>University of Nevada, Reno
  </div>
  <div>
    <img src="/assets/img/sandeep.png" alt="Sandeep Kumar"><br>
    <strong>Sandeep Kumar</strong><br>IIT Delhi
  </div>
  <div>
    <img src="/assets/img/amrit.jpg" alt="Amrit Singh Bedi"><br>
    <strong>Amrit Singh Bedi</strong><br>University of Central Florida
  </div>
  <div>
    <img src="/assets/img/tanmoy.png" alt="Tanmoy Chakraborty"><br>
    <strong>Tanmoy Chakraborty</strong><br>IIT Delhi
  </div>
</div>

---

## ‚úâÔ∏è <a id="contact"></a> Contact

For any queries, email us at:  
üìß [ankitas@unr.edu](mailto:ankitas@unr.edu)
