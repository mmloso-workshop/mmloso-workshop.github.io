---
layout: default
title: Welcome to MMLoSo 2025
---

<style>
.container {
  display: flex;
  align-items: flex-start;
  gap: 40px;
  max-width: 1400px;
  margin: 0 auto;
  padding: 20px;
}
.sidebar {
  flex: 0 0 280px;
}
.content {
  flex: 1;
  max-width: 900px;
}
.sidebar a.button {
  display: block;
  margin: 8px 0;
  padding: 10px 14px;
  background-color: #005a9c;
  color: white;
  border-radius: 6px;
  text-decoration: none;
  text-align: center;
}
.sidebar a.openreview {
  display: inline-block;
  background-color: #2e7dd8;
  margin-bottom: 15px;
}
</style>

<div class="container">

<div class="sidebar">
  <h3>MMLoSo Workshop @ IJCNP-AACL 2025</h3>
  <p style="font-size: 13px;">
    First International Workshop on<br>
    Multimodal Models for Low-Resource Contexts and Social Impact
  </p>
  <a class="button openreview" href="https://openreview.net/group?id=aclweb.org/AACL-IJCNLP/2025/Workshop/MMLoSo" target="_blank">
    ğŸ”— View on OpenReview
  </a>
  <a class="button" href="#about">About</a>
  <a class="button" href="#cfp">Call for Papers</a>
  <a class="button" href="#dates">Important Dates</a>
  <a class="button" href="#organizers">Organizers</a>
  <a class="button" href="#contact">Contact</a>
</div>

<div class="content">

# MMLoSo 2025
**Multimodal Models for Low-Resource Contexts and Social Impact**  
ğŸ“ Co-located with IJCNLP-AACL 2025  
ğŸ“… December 2025, Mumbai, India

---

## ğŸ“– <a id="about"></a> About

This workshop brings together researchers at the intersection of multimodal learning, NLP, and AI for social good, with a focus on low-resource and underserved settings. While multimodal dataâ€”text, audio, visual, and sensorâ€”continues to grow, most state-of-the-art models depend on large, high-quality datasets, limiting their applicability in data-scarce environments.

We invite papers on developing robust and inclusive multimodal systems that can operate effectively under data constraints. Topics include learning with multiple modalities, cross-lingual, cross-modal adaptation, and interpretable models for domains like healthcare, ecological monitoring, education, and cultural heritage preservation. Alongside papers and keynotes, a community-driven shared task will evaluate multimodal robustness and generalization in low-resource contexts.

---

## ğŸ“¢ <a id="cfp"></a> Call for Papers

We focus on bridging the gap between the growing capabilities of multimodal machine learning models and the urgent needs of real-world applications in under-resourced, marginalized, or data-constrained settings. This includes scenarios where data is scarce, modalities are incomplete or imbalanced, and computational or human infrastructure may be limited.

The topics of interest for the workshop include, but are not limited to:

- **Learning with Missing or Incomplete Modalities**  
- **Few-Shot, Zero-Shot, and Transfer Learning in Multimodal Contexts**  
- **Multilingual and Multimodal Representation Learning**  
- **Ethical, Interpretable, and Responsible AI for Multimodal Systems**  
- **Benchmarking and Evaluation for Real-World Robustness**  
- **Applications in Social Good**, including biodiversity monitoring, public health, language documentation, crisis response.

---

## ğŸ“… <a id="dates"></a> Important Dates
*(Subject to change based on IJCNLP-AACL 2025)*

- ğŸ“ Submission Deadline: **September 29, 2025**
- ğŸ“¢ Notification: **November 3, 2025**
- ğŸ–‹ Camera-ready Deadline: **November 11, 2025**
- ğŸ“ Workshop: **December 23, 2025**

---

## ğŸ‘¥ <a id="organizers"></a> Organizers
- Ankita Shukla (University of Nevada, Reno)
- Sandeep Kumar (IIT Delhi)
- Amrit Singh Bedi (University of Central Florida)
- Tanmoy Chakraborty (IIT Delhi)

---

## âœ‰ï¸ <a id="contact"></a> Contact
For any queries, email us at:  
ğŸ“§ [ankitas@unr.edu](mailto:ankitas@unr.edu)

</div>
</div>
